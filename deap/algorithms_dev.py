import array
import sys
import numpy as np
import math
from sklearn.metrics import mutual_info_score
import networkx as nx
from collections import defaultdict
from deap import tools
from collections import Counter
import pandas as pd
import matplotlib.pyplot as plt


'''
#################################################################################################
UMDA ALGORITHM AND AUXILIAR FUNCTIONS
#################################################################################################
'''
cardinalitiesUMDA=[]
vectorProbabilities=[]


def initCardinality(card):
# This function initializes the array of cardinalities    
    global cardinalitiesUMDA
    cardinalitiesUMDA=card


def createModel(popul):
# This function counts the frequencies of every value for every variable and stores it in the vector of probabilities
# In order to avoid the lack of diversity generated by null values, it corrects this by adding 1 to all the sums.
       
    numberOfVariables=len(popul[0])
    counterProbabilities= [None]*numberOfVariables
    for i in range(numberOfVariables):
        counterProbabilities=Counter(np.transpose(popul)[i])
        for j in range(cardinalitiesUMDA[i]):    
           vectorProbabilities[i][j]= (1 + counterProbabilities[j])/(len(popul)+cardinalitiesUMDA[i])
          

def generateNewPopulation(population):
# This function samples a new population using the data of the model that has been stored in the vector of probabilities    
        
    numberOfVariables=len(population[0])
    #print("number of ")
    # It generates a population with N number of individuals, being numberOfVariables the size of every individual
    for i in range(len(population)):
        for j in range(numberOfVariables):
            #print(vectorProbabilities[j]) 
            population[i][j]=np.random.choice(cardinalitiesUMDA[j],p=vectorProbabilities[j])

    return population

def umda(population, toolbox, sizesel,card, ngen, halloffame=None, stats=None,verbose=__debug__):
# This function executes the UMDA algorithm     
    initCardinality(card)
    print(population) 
    logbook = tools.Logbook() 
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])
    numberOfVariables=len(population[0])
    global vectorProbabilities

    for i in range(numberOfVariables):
        #vectorProbabilities=np.zeros((numberOfVariables,maxValue+1))
        vectorProbabilities.append( [0]*cardinalitiesUMDA[i] )
    #Fill the vector with 0s.


    # Create ngen generations
    for gen in range(1, ngen + 1):
           
            # Evaluate the individuals
            fitnesses = toolbox.map(toolbox.evaluate, population)
        
            for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit

            # Select sizeOfSelection individuals according to the best fitness
            sizeOfSelection=sizesel
            offspring= toolbox.select(population, sizeOfSelection)
            
            # Calculate the probability distribution of the chosen individuals
            createModel(offspring)

            # Generate the new population using these probabilities 
            population=generateNewPopulation(population)
           
            
            record = stats.compile(population) if stats is not None else {}
            logbook.record(gen=gen, nevals=len(population), **record)
            if verbose:
                  print(logbook.stream)
    print("The vector of probabilities after the last generation is:")
    print(vectorProbabilities)
    return population, logbook

'''
#################################################################################################
TREE-EDA ALGORITHM AND AUXILIAR FUNCTIONS
#################################################################################################
'''


# FM(Frequency Matrix) stores in the amout the frequencies that a variable0 has a value0, when the variable1 is value1
data = {"x0": [], "x1": [],"value0": [], "value1": [],"frequency": []}
fm = pd.DataFrame(data)
""""
data = {"x0": [0,1], "x1": [1,2],"value0": [1,0], "value1": [6,6],"frequency": [2,25]}
Meaning:the frequency of x0=1, being x1=6 is 2
Meaning:the frequency of x1=0, being x2=6 is 25

NOTE: alternatively we could use numpy arrays instead of pandas dataframes to store the frequencies.
fm = np.array([
    [0, 1, 1, 6, 2],
    [1, 2, 0, 6, 25]
    ...
])

"""
# Number of variables of the population individuals. It will be initialized by the init functions
numvar = 0
population=[]
# Auxiliar list to fill with individual data while traversing the tree
newIndividual=[]
cardinalitiesTree=[]

def treeEDA(pop, toolbox, sizeSel, card, ngen, halloffame=None, stats=None,verbose=__debug__,vbse=False):
# Executes the treeEDA algorithm     
    
    global population 
    global numvar
    global newIndividual
    global cardinalitiesTree
    population = pop
    numvar = len(population[0])
    newIndividual=[0]*numvar
    cardinalitiesTree = card
    
    initFrequencyMatrix()
    addFrequenciestoMatrix(population) 
    logbook = tools.Logbook() 
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])
    
    for gen in range (ngen):
        # The model is created from the data stored in the Frequency Matrix.
        tree=createMSPfromMI(verbose=False)
        
        # We traverse the tree populationSize times. In every loop a new individual is added to the population
        for i in range(len(population)):
            traverseTree(tree,vbse=False)
            for j in range(numvar):
                population[i][j]=newIndividual[j]
        
        # We analyze the fitness according to the benchmark function
        fitnesses = toolbox.map(toolbox.evaluate, population)
        for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit

        # Select sizeSel individuals according to the best fitness
        selPop= toolbox.select(population, sizeSel)        
        
        record = stats.compile(population) if stats is not None else {}
        logbook.record(gen=gen, nevals=len(population), **record)
        if verbose:
                  print(logbook.stream)
        #Apply the decay factor to all elements of the frequency matrix
        applyDecayfactor(0.99)
        
        # We add the frequencies to the matrix from the selected population 
        addFrequenciestoMatrix(selPop) 
    
    return population, logbook

def initFrequencyMatrix():
# Initializes all 'frequency' values of the frequenty matrix to 0. 
    global numvar
    global cardinalitiesTree
    global fm
    global data
    
    newIndividual=[0]*numvar
    for i in range(numvar):
        for j in range(i+1,numvar):
             for k in range(cardinalitiesTree[i]):
                 for h in range(cardinalitiesTree[j]):
                    data["x0"].append(i)
                    data["x1"].append(j)  
                    data["value0"].append(k) 
                    data["value1"].append(h)  
                    data["frequency"].append(0) 
    fm = pd.DataFrame(data)

def addFrequenciestoMatrix(selectedPop):
    global fm
    for i in range(numvar):
        for j in range(i+1,numvar):
            for k in range(len(selectedPop)):
               fm.loc[(fm['x0'] == i) & (fm['x1'] == j)& (fm['value0'] == selectedPop[k][i]) & (fm['value1'] == selectedPop[k][j]),'frequency']+=1   
              
def getUnivariate(x,value):
# Returns the univariate frequency in the frequency matrix for the given 'x' variable and 'value' value
    
    propFreq=1/cardinalitiesTree[x]
    total=fm.loc[(fm['x0'] == 0) & (fm['x1'] == 1),'frequency'].sum()
    # In the case of x=0, it makes no sense to look for fm[(0,0)]. We use the data of fm[(0,1)], adjsuting 
    # the indexes so that returns the values of the X0 bit and not X1. 
    if total!=0:
        if x>0:
            freq= fm.loc[(fm['x1'] == x) & (fm['x0']==0) & (fm['value1']==value) , 'frequency'].sum()/total
        else:    
            freq= fm.loc[(fm['x1'] == 1) & (fm['x0']==0) & (fm['value0']==value) , 'frequency'].sum()/total
        return freq
    else:
        return 1/cardinalitiesTree[x]
        
def getConditionalFrequency(x0,x1,value0,value1):
# Returns a list with the frequency for x0=0,x0=1 values, giving fixed that x1=value1

    propFreq=1/cardinalitiesTree[x0]
    if x0>x1: 
        x0,x1=x1,x0
        value0,value1=value1,value0
        normTotal=fm.loc[(fm['x0']==x0) & (fm['x1'] == x1) & (fm['value0']==value0 ), 'frequency'].sum()  
        
    else:
        normTotal=fm.loc[(fm['x0']==x0) & (fm['x1'] == x1)  & (fm['value1']==value1 ), 'frequency'].sum()
    
    if normTotal!=0:
            
            freq= fm.loc[(fm['x0']==x0) &  (fm['x1'] == x1) &(fm['value0']==value0) & (fm['value1']==value1 ), 'frequency'].sum()/normTotal
            return freq
    else:
            return propFreq
   
def getBivariate(x0,x1,value0,value1):
    total=fm.loc[(fm['x0'] == 0)& (fm['x1'] == 1) ,'frequency'].sum()
    if total!=0:
        return fm.loc[(fm['x0']==x0) & (fm['x1']==x1) & (fm['value0']==value0) & (fm['value1']==value1),'frequency'].sum()/total
    else:
        return 0

def getMutualInfo(x0,x1):
# Returns the mutual information of two given variables 

    if x0>x1: 
        x0,x1=x1,x0
    mutual=0
   
    for value0 in range(cardinalitiesTree[x0]): 
        for value1 in range(cardinalitiesTree[x1]):
           # print("n.a Bivariate/Univariate values when X0X1="+str(value0)+str(value1))
           # print(getUnivariateInteger(x0,value0),getUnivariateInteger(x1,value1),getBivariate(x0,x1,value0,value1))
            if (getBivariate(x0,x1,value0,value1)!=0 and getUnivariate(x0,value0)!=0 and getUnivariate(x1,value1)!=0):
                mutual=mutual+ getBivariate(x0,x1,value0,value1)* math.log(getBivariate(x0,x1,value0,value1)/(getUnivariate(x0,value0)*getUnivariate(x1,value1))) 
    
    return mutual


def dfs_edges(G, source=None, depth_limit=None, vbse=False):
    """
    This function is based on the Depth First function of the networkx library. 
    Modificarions have been done in order to go creating the bits of the individuals while traversing the tree.

    Iterate over edges in a depth-first-search (DFS).

    Parameters
    ----------
    G : NetworkX graph

    source : node, optional
       Specify starting node for depth-first search and return edges in
       the component reachable from source.

    depth_limit : int, optional (default=len(G))
       Specify the maximum search depth.

    Returns
    -------
    edges: generator
       A generator of edges in the depth-first-search.

    Examples
    --------
    >>> G = nx.path_graph(5)
    >>> list(nx.dfs_edges(G, source=0))
    [(0, 1), (1, 2), (2, 3), (3, 4)]
    >>> list(nx.dfs_edges(G, source=0, depth_limit=2))
    [(0, 1), (1, 2)]
"""
    global newIndividual
    if source is None:
        # edges for all components
        nodes = G
    else:
        # edges for components with source
        nodes = [source]
    visited = set()
    if depth_limit is None:
        depth_limit = len(G)
    for start in nodes:
        if start in visited:
            continue
        visited.add(start)
        stack = [(start, depth_limit, iter(G[start]))]
        fqList=[]
        frequencyList=[]
        for freq1 in range(cardinalitiesTree[start]):
            fqList.append(getUnivariate(start,freq1))
        newIndividual[start]=np.random.choice(len(fqList),p=fqList)
        
        if vbse:
            print("Starting to traverse from the root ")
            print("for x"+str(start)+" creates:"+ str(newIndividual[start]))
        while stack:
            parent, depth_now, children = stack[-1]
            try:
                child = next(children)
                if child not in visited:
                    yield parent, child
                    visited.add(child)
                    if depth_now > 1:
                        
                        stack.append((child, depth_now - 1, iter(G[child])))
                        for freq in range(cardinalitiesTree[child]):
                            frequencyList.append(getConditionalFrequency(child,parent,freq,newIndividual[parent]))
                        newIndividual[child]=np.random.choice(len(frequencyList),p=frequencyList)
                        frequencyList=[]
                        if vbse:
                                print("for x"+str(child)+" creates:"+ str(newIndividual[child]) +" from a conditional probability of "+ str(getConditionalFrequency(child,parent,newIndividual[child],newIndividual[parent]))+" being parent x"+str(parent)+"="+str(newIndividual[parent]) )
            except StopIteration:
                stack.pop() 
               

def dfs_successors(G, source=None, depth_limit=None, vbse=False):
    """Return dictionary of successors in depth-first-search from source.

    Parameters
    ----------
    G : NetworkX graph

    source : node, optional
       Specify starting node for depth-first search and return edges in
       the component reachable from source.

    depth_limit : int, optional (default=len(G))
       Specify the maximum search depth.

    Returns
    -------
    succ: dict
       A dictionary with nodes as keys and list of successor nodes as values.

    Examples
    --------
    >>> G = nx.path_graph(5)
    >>> nx.dfs_successors(G, source=0)
    {0: [1], 1: [2], 2: [3], 3: [4]}
    >>> nx.dfs_successors(G, source=0, depth_limit=2)
    {0: [1], 1: [2]}

    Notes
    -----
    If a source is not specified then a source is chosen arbitrarily and
    repeatedly until all components in the graph are searched.

    The implementation of this function is adapted from David Eppstein's
    depth-first search function in `PADS`_, with modifications
    to allow depth limits based on the Wikipedia article
    "`Depth-limited search`_".

    .. _PADS: http://www.ics.uci.edu/~eppstein/PADS
    .. _Depth-limited search: https://en.wikipedia.org/wiki/Depth-limited_search
    """
    d = defaultdict(list)
    for s, t in dfs_edges(G, source=None, depth_limit=depth_limit, vbse=vbse):
        d[s].append(t)

    return dict(d) 

def applyDecayfactor(factor):
# Decreases the values of all elements of the frequency matrix by a given factor 
    global fm
    fm['frequency'] *= factor
   


               
def createMSPfromMI(verbose=False):
# This function creates a graph which contains the minimum spanning tree. In order to do so, it iterates all the variable-pair combinations 
# the frequency matrix,calculating the Mutual Information. This value is added as the weight to the edges that represent the variable-pairs in the 
# Mutual Information graph. Then this graph is used to create the graph with the minimum spanning tree.

  
    MIGraph=nx.empty_graph(numvar)
   
 
    for i in range(numvar):
        for j in range(i+1,numvar):
             MIGraph.add_edge(i,j,weight=getMutualInfo(i,j)*-1)
    
      
    if verbose:
         print("THE ENTIRE GRAPH\n")
         print(sorted(MIGraph.edges(data=True))) 
         print("\n")
         print("THE NODE CONNECTIONS OF THE MINIMUM TREE:\n")
         print(nx.minimum_spanning_tree(MIGraph).edges(data=True))
         print("\n")
    
    #nx.draw_networkx(nx.minimum_spanning_tree(MIGraph),cmap = plt.get_cmap('jet'),with_labels=True,pos=nx.spring_layout(nx.minimum_spanning_tree(MIGraph)))
    #plt.show() 
    
    return nx.minimum_spanning_tree(MIGraph)


def traverseTree(T, vbse=False):
# Traverse the tree for creating the new individuals
    dfs_successors(T,vbse=vbse)
        
    
   
