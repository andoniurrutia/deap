import array
import sys
import numpy as np
import math
from sklearn.metrics import mutual_info_score
import networkx as nx
from collections import defaultdict
from deap import tools
from collections import Counter
import pandas as pd
import matplotlib.pyplot as plt


'''
#################################################################################################
UMDA ALGORITHM AND AUXILIAR FUNCTIONS
#################################################################################################
'''
cardinalities=[]
vectorProbabilities=[]


def initCardinality(card):
# Thus function initializes the array of cardinalities    
    global cardinalities
    cardinalities=card


def createModel(popul):
# This function counts the frequencies of every value for every variable and stores it in the vector of probabilities
# In order to avoid the lack of diversity generated by null values, it corrects this by adding 1 to all the sums.
       
    numberOfVariables=len(popul[0])
    counterProbabilities= [None]*numberOfVariables
    for i in range(numberOfVariables):
        counterProbabilities=Counter(np.transpose(popul)[i])
        for j in range(cardinalities[i]):    
           vectorProbabilities[i][j]= (1 + counterProbabilities[j])/(len(popul)+cardinalities[i])
          

def generateNewPopulation(population):
# This function samples a new population using the data of the model that has been stored in the vector of probabilities    
        
    numberOfVariables=len(population[0])
    #print("number of ")
    # It generates a population with N number of individuals, being numberOfVariables the size of every individual
    for i in range(len(population)):
        for j in range(numberOfVariables):
            #print(vectorProbabilities[j]) 
            population[i][j]=np.random.choice(cardinalities[j],p=vectorProbabilities[j])

    return population

def umda(population, toolbox, sizesel,card, ngen, halloffame=None, stats=None,verbose=__debug__):
# This function executes the UMDA algorithm     
    initCardinality(card)
    print(population) 
    logbook = tools.Logbook() 
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])
    numberOfVariables=len(population[0])
    global vectorProbabilities

    for i in range(numberOfVariables):
        #vectorProbabilities=np.zeros((numberOfVariables,maxValue+1))
        vectorProbabilities.append( [0]*cardinalities[i] )
    #Fill the vector with 0s.


    # Create ngen generations
    for gen in range(1, ngen + 1):
           
            # Evaluate the individuals
            fitnesses = toolbox.map(toolbox.evaluate, population)
        
            for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit

            # Select sizeOfSelection individuals according to the best fitness
            sizeOfSelection=sizesel
            offspring= toolbox.select(population, sizeOfSelection)
            
            # Calculate the probability distribution of the chosen individuals
            createModel(offspring)

            # Generate the new population using these probabilities 
            population=generateNewPopulation(population)
           
            
            record = stats.compile(population) if stats is not None else {}
            logbook.record(gen=gen, nevals=len(population), **record)
            if verbose:
                  print(logbook.stream)
    print("The vector of probabilities after the last generation is:")
    print(vectorProbabilities)
    return population, logbook

'''
#################################################################################################
TREE-EDA ALGORITHM AND AUXILIAR FUNCTIONS
#################################################################################################
'''

###
#Idea for entire numbers: posVarPairsValues
#cardinality 0:2 and cardinality 1:3
#The Frequency Matrix (0,1) -->[(0,0)-->N,(0,1)-->N2,(0,2)-->N,1,0,1,1,1,2]
# at generation time is when we look at the cardinalities
#fm={(0,1):[[0,0,2],[0,1,3]]}

#fm=[[0,1,0,1,1]]
#df.loc[df['a'] == 1, 'b'].sum()
# FM(Frequency Matrix) stores the frequencies of all x0x1=00,01,10,11 combinations for every pair of variables x0,x1
fm={}

#Possible variable pair values: 00,01,10,11
posVarPairsValues=4

#Number of variables of the population individuals. It will be initialized by the init functions
numvar=0

#List data structure to store populations and an auxiliar list to fill with individuals data while 
#traversing the tree
population=[]
newIndividual=[]

data = {"x0": [], "x1": [],"value0": [], "value1": [],"amount": []}
df = pd.DataFrame(data)


def init(value,numvarInit,popInit,card):
# This function initializes the data structures that the algorithm is going to use. 
# Params: 
#   value: the initial value that it is going to be assigned to all the elements of the Frequency Matrix 
#   numvarInit: sizes of the population individuals
#   popInit: initial population
 
    global numvar
    global newIndividual
    global population
    global cardinalities


    population=popInit           
     
    numvar=numvarInit 
    newIndividual=[0]*numvar
     
    for i in range(numvar):
        for j in range(i+1,numvar):
          fm.update({(i,j):np.array([value]*posVarPairsValues)})  
    cardinalities=card


def init(value,numvarInit,popInit,card):
# This function initializes the data structures that the algorithm is going to use. 
# Params: 
#   value: the initial value that it is going to be assigned to all the elements of the Frequency Matrix 
#   numvarInit: sizes of the population individuals
#   popInit: initial population

    global numvar
    global newIndividual
    global population
    global df
    global data
    global cardinalities
    
    population=popInit           
    cardinalities=card
    numvar=numvarInit 
    newIndividual=[0]*numvar
    
    for i in range(numvar):
        for j in range(i+1,numvar):
             
             for k in range(cardinalities[i]):
                 for h in range(cardinalities[j]):
                   
                    data["x0"].append(i)
                    data["x1"].append(j)  
                    data["value0"].append(k) 
                    data["value1"].append(h)  
                    data["amount"].append(value) 

    #print(data)    
    df = pd.DataFrame(data)
    
              
def getUnivariate(x,value):
    # Returns the univariate frequency of the given x variable
    
    propFreq=1/cardinalities[x]
    total=df.loc[(df['x0'] == 0) & (df['x1'] == 1),'amount'].sum()
    #print("TOTAL IS"+str(total))
  
    
        
    # In the case of x=0, it makes no sense to look for fm[(0,0)]. We use the data of fm[(0,1)], adjsuting 
    # the indexes so that returns the values of the X0 bit and not X1. 
    if total!=0:
        if x>0:
       
            freq= df.loc[(df['x1'] == x) & (df['x0']==0) & (df['value1']==value) , 'amount'].sum()/total
        else:    
            freq= df.loc[(df['x1'] == 1) & (df['x0']==0) & (df['value0']==value) , 'amount'].sum()/total

    
        return freq
    else:
        return 1/cardinalities[x]
        #return 0


def getConditionalFrequency(x0,x1,value0,value1):
# Returns a list with the frequency for x0=0,x0=1 values, giving fixed that x1=value1

    propFreq=1/cardinalities[x0]
    if x0>x1: 
        x0,x1=x1,x0
        value0,value1=value1,value0
        normTotal=df.loc[(df['x0']==x0) & (df['x1'] == x1) & (df['value0']==value0 ), 'amount'].sum()  
        
    else:
        normTotal=df.loc[(df['x0']==x0) & (df['x1'] == x1)  & (df['value1']==value1 ), 'amount'].sum()
    
    if normTotal!=0:
            
            freq= df.loc[(df['x0']==x0) &  (df['x1'] == x1) &(df['value0']==value0) & (df['value1']==value1 ), 'amount'].sum()/normTotal
            return freq
    else:
            return propFreq
   
       
      

def getBivariate(x0,x1,value0,value1):
    total=df.loc[(df['x0'] == 0)& (df['x1'] == 1) ,'amount'].sum()
    if total!=0:
        return df.loc[(df['x0']==x0) & (df['x1']==x1) & (df['value0']==value0) & (df['value1']==value1),'amount'].sum()/total
    else:
        return 0

def getMutualInfo(x0,x1):
# Returns the mutual information of two given variables 

    if x0>x1: 
        x0,x1=x1,x0
    mutual=0
   
    for value0 in range(cardinalities[x0]): 
        for value1 in range(cardinalities[x1]):
           # print("n.a Bivariate/Univariate values when X0X1="+str(value0)+str(value1))
           # print(getUnivariateInteger(x0,value0),getUnivariateInteger(x1,value1),getBivariate(x0,x1,value0,value1))
            if (getBivariate(x0,x1,value0,value1)!=0 and getUnivariate(x0,value0)!=0 and getUnivariate(x1,value1)!=0):
                mutual=mutual+ getBivariate(x0,x1,value0,value1)* math.log(getBivariate(x0,x1,value0,value1)/(getUnivariate(x0,value0)*getUnivariate(x1,value1))) 
    
    return mutual


def dfs_edges(G, source=None, depth_limit=None, vbse=False):
    """
    This function is based on the Depth First function of the networkx library. 
    Modificarions have been done in order to go creating the bits of the individuals while traversing the tree.

    Iterate over edges in a depth-first-search (DFS).

    Parameters
    ----------
    G : NetworkX graph

    source : node, optional
       Specify starting node for depth-first search and return edges in
       the component reachable from source.

    depth_limit : int, optional (default=len(G))
       Specify the maximum search depth.

    Returns
    -------
    edges: generator
       A generator of edges in the depth-first-search.

    Examples
    --------
    >>> G = nx.path_graph(5)
    >>> list(nx.dfs_edges(G, source=0))
    [(0, 1), (1, 2), (2, 3), (3, 4)]
    >>> list(nx.dfs_edges(G, source=0, depth_limit=2))
    [(0, 1), (1, 2)]
"""
    global newIndividual
    if source is None:
        # edges for all components
        nodes = G
    else:
        # edges for components with source
        nodes = [source]
    visited = set()
    if depth_limit is None:
        depth_limit = len(G)
    for start in nodes:
        if start in visited:
            continue
        visited.add(start)
        stack = [(start, depth_limit, iter(G[start]))]
        fqList=[]
        frequencyList=[]
        for freq1 in range(cardinalities[start]):
            fqList.append(getUnivariate(start,freq1))
        newIndividual[start]=np.random.choice(len(fqList),p=fqList)
        
        if vbse:
            print("Starting to traverse from the root ")
            print("for x"+str(start)+" creates:"+ str(newIndividual[start]))
        while stack:
            parent, depth_now, children = stack[-1]
            try:
                child = next(children)
                if child not in visited:
                    yield parent, child
                    visited.add(child)
                    if depth_now > 1:
                        
                        stack.append((child, depth_now - 1, iter(G[child])))
                        for freq in range(cardinalities[child]):
                            frequencyList.append(getConditionalFrequency(child,parent,freq,newIndividual[parent]))
                        newIndividual[child]=np.random.choice(len(frequencyList),p=frequencyList)
                        frequencyList=[]
                        if vbse:
                                print("for x"+str(child)+" creates:"+ str(newIndividual[child]) +" from a conditional probability of "+ str(getConditionalFrequency(child,parent,newIndividual[child],newIndividual[parent]))+" being parent x"+str(parent)+"="+str(newIndividual[parent]) )
            except StopIteration:
                stack.pop() 
               

def dfs_successors(G, source=None, depth_limit=None, vbse=False):
    """Return dictionary of successors in depth-first-search from source.

    Parameters
    ----------
    G : NetworkX graph

    source : node, optional
       Specify starting node for depth-first search and return edges in
       the component reachable from source.

    depth_limit : int, optional (default=len(G))
       Specify the maximum search depth.

    Returns
    -------
    succ: dict
       A dictionary with nodes as keys and list of successor nodes as values.

    Examples
    --------
    >>> G = nx.path_graph(5)
    >>> nx.dfs_successors(G, source=0)
    {0: [1], 1: [2], 2: [3], 3: [4]}
    >>> nx.dfs_successors(G, source=0, depth_limit=2)
    {0: [1], 1: [2]}

    Notes
    -----
    If a source is not specified then a source is chosen arbitrarily and
    repeatedly until all components in the graph are searched.

    The implementation of this function is adapted from David Eppstein's
    depth-first search function in `PADS`_, with modifications
    to allow depth limits based on the Wikipedia article
    "`Depth-limited search`_".

    .. _PADS: http://www.ics.uci.edu/~eppstein/PADS
    .. _Depth-limited search: https://en.wikipedia.org/wiki/Depth-limited_search
    """
    d = defaultdict(list)
    for s, t in dfs_edges(G, source=None, depth_limit=depth_limit, vbse=vbse):
        d[s].append(t)

    return dict(d) 

def applyDecayfactor(factor):
# Decreases the values of all elements of the frequency matrix by a given factor 
   
    global fm
    for key in fm:
            fm[key]*=factor
   

def addFrequenciestoMatrix(selectedPop):
    global df
    for i in range(numvar):
        for j in range(i+1,numvar):
            for k in range(len(selectedPop)):
               df.loc[(df['x0'] == i) & (df['x1'] == j)& (df['value0'] == selectedPop[k][i]) & (df['value1'] == selectedPop[k][j]),'amount']+=1
               
def createMSPfromMI(verbose=False):
# This function creates a graph which contains the minimum spanning tree. In order to do so, it iterates all the variable-pair combinations 
# the frequency matrix,calculating the Mutual Information. This value is added as the weight to the edges that represent the variable-pairs in the 
# Mutual Information graph. Then this graph is used to create the graph with the minimum spanning tree.

  
    MIGraph=nx.empty_graph(numvar)
   
 
    for i in range(numvar):
        for j in range(i+1,numvar):
             MIGraph.add_edge(i,j,weight=getMutualInfo(i,j)*-1)
    
      
    if verbose:
         print("THE ENTIRE GRAPH\n")
         print(sorted(MIGraph.edges(data=True))) 
         print("\n")
         print("THE NODE CONNECTIONS OF THE MINIMUM TREE:\n")
         print(nx.minimum_spanning_tree(MIGraph).edges(data=True))
         print("\n")
    
    nx.draw_networkx(nx.minimum_spanning_tree(MIGraph),cmap = plt.get_cmap('jet'),with_labels=True,pos=nx.spring_layout(nx.minimum_spanning_tree(MIGraph)))
    plt.show() 
    
    return nx.minimum_spanning_tree(MIGraph)


def traverseTree(T, vbse=False):
# Traverse the tree for creating the new individuals
    dfs_successors(T,vbse=vbse)
        
    
   
def treeEDA(population,toolbox, sizeSel,card,ngen, halloffame=None, stats=None,verbose=__debug__,vbse=False):
# This function executes the treeEDA algorithm     
    init(0,len(population[0]), population,card)
 
    addFrequenciestoMatrix(population) 
    logbook = tools.Logbook() 
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])
    
    for gen in range (ngen):
        # The model is created from the data stored in the Frequency Matrix.
        tree=createMSPfromMI(verbose=False)
        
        # We traverse the tree populationSize times. In every loop a new individual is added to the population
        for i in range(len(population)):
            traverseTree(tree,vbse=False)
            for j in range(numvar):
                population[i][j]=newIndividual[j]
        
        # We analyze the fitness according to the benchmark function
        fitnesses = toolbox.map(toolbox.evaluate, population)
        for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit

        # Select sizeOfSelection individuals according to the best fitness
        sizeOfSelection=sizeSel
        selPop= toolbox.select(population, sizeOfSelection)        
        
        record = stats.compile(population) if stats is not None else {}
        logbook.record(gen=gen, nevals=len(population), **record)
        if verbose:
                  print(logbook.stream)
        #Apply the decay factor to all elements of the frequency matrix
        applyDecayfactor(0.99)
        
        # We add the frequencies to the matrix from the selected population 
        addFrequenciestoMatrix(selPop) 
    
    return population, logbook