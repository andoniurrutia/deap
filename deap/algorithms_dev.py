import array
import sys
import numpy as np
import math
from sklearn.metrics import mutual_info_score
import networkx as nx
from collections import defaultdict
from deap import tools
from collections import Counter


'''
#################################################################################################
UMDA ALGORITHM AND AUXILIAR FUNCTIONS
#################################################################################################
'''

vectorProbabilities=[]

def createModel(popul,maxValue):
# This function counts the frequencies of every value for every value and stores it in the vector of probabilities
# In order to avoid lack of diversity generated by null values, it corrects this by adding 1 to all the sums.
        
    numberOfVariables=len(popul[0])
    counterProbabilities= [None]*numberOfVariables
    for i in range(numberOfVariables):
        counterProbabilities=Counter(np.transpose(popul)[i])
        for j in range(maxValue+1):    
           vectorProbabilities[i][j]= (1 + counterProbabilities[j])/(len(popul)+maxValue+1)
              
def generateNewPolulation(population,maxValue):
# This function samples a new population using the data of the model that has been stored in the vector of probabilities    
        
    numberOfVariables=len(population[0])
    # It generates a population with N number of individuals, being numberOfVariables the size of every individual
    for i in range(len(population)):
        for j in range(numberOfVariables):
            population[i][j]=np.random.choice(maxValue+1,p=vectorProbabilities[j])
    return population

def umda(population, toolbox, ngen, maxValue, halloffame=None, stats=None,verbose=__debug__):
# This function executes the UMDA algorithm     
    
    logbook = tools.Logbook() 
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])
    numberOfVariables=len(population[0])
    global vectorProbabilities

    vectorProbabilities=np.zeros((numberOfVariables,maxValue+1))
    
    # Create ngen generations
    for gen in range(1, ngen + 1):
           
            # Evaluate the individuals
            fitnesses = toolbox.map(toolbox.evaluate, population)
        
            for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit

            # Select sizeOfSelection individuals according to the best fitness
            sizeOfSelection=int(sys.argv[1:][4])
            offspring= toolbox.select(population, sizeOfSelection)
            
            # Calculate the probability distribution of the chosen individuals
            createModel(offspring,maxValue)

            # Generate the new population using these probabilities 
            population=generateNewPolulation(population,maxValue)
           
            
            record = stats.compile(population) if stats is not None else {}
            logbook.record(gen=gen, nevals=len(population), **record)
            if verbose:
                  print(logbook.stream)
    print("The vector of probabilities after the last generation is:")
    print(vectorProbabilities)
    return population, logbook

'''
#################################################################################################
TREE-EDA ALGORITHM AND AUXILIAR FUNCTIONS
#################################################################################################
'''

# FM(Frequency Matrix) stores the frequencies of all x0x1=00,01,10,11 combinations for every pair of variables x0,x1
fm={}

#Possible variable pair values: 00,01,10,11
posVarPairsValues=4

#Number of variables of the population individuals. It will be initialized by the init functions
numvar=0

#List data structure to store populations and an auxiliar list to fill with individuals data while 
#traversing the tree
population=[]
newIndividual=[]


def init(value,numvarInit,popInit):
# This function initializes the data structures that the algorithm is going to use. 
# Params: 
#   value: the initial value that it is going to be assigned to all the elements of the Frequency Matrix 
#   numvarInit: sizes of the population individuals
#   popInit: initial population

    global numvar
    global newIndividual
    global population
    
    population=popInit           
    
    numvar=numvarInit 
    newIndividual=[0]*numvar
    
    for i in range(numvar):
        for j in range(i+1,numvar):
          fm.update({(i,j):np.array([value]*posVarPairsValues)})  

def getUnivariate(x):
# Returns the univariate frequency of the given x variable
    total=sum(fm[(0,1)])
  
    if x>0:
        return [(fm[(0,x)][0]+fm[(0,x)][2])/total,(fm[(0,x)][1]+fm[(0,x)][3])/total]
    
    # In the case of x=0, it makes no sense to look for fm[(0,0)]. We use the data of fm[(0,1)], adjsuting 
    # the indexes so that returns the values of the X0 bit and not X1. 
    else:
        return [(fm[(0,1)][0]+fm[(0,1)][1])/total,(fm[(0,1)][2]+fm[(0,1)][3])/total]
       
  
def getConditionalFrequency(x0,x1,value1):
# Returns a list with the frequency for x0=0,x0=1 values, giving fixed that x1=value1

    if x0>x1: 
        x0,x1=x1,x0
        #value0,value1=value1,value0
        normTotal=fm[(x0,x1)][int(value1)]+fm[(x0,x1)][int(value1+2)]
        myList=[fm[(x0,x1)][int(value1)],fm[(x0,x1)][int(value1+2)] ] 
        return [x / normTotal for x in myList]
   
    else:
        normTotal=fm[(x0,x1)][int(value1*2)]+fm[(x0,x1)][int(value1*2+1)] 
        myList= [fm[(x0,x1)][int(value1*2)],fm[(x0,x1)][int(value1*2+1)] ]
        return [x / normTotal for x in myList]    

def getMutualInfo(x0,x1):
# Returns the mutual information of two given variables 

    if x0>x1: 
        x0,x1=x1,x0
    mutual=0
    
    univariateProbX0=getUnivariate(x0)
    univariateProbX1=getUnivariate(x1)

    for i in range(posVarPairsValues):    
        indX0=int(i/2)
        indX1=i%2
        #print("Bivariate/Univariate values when X0X1="+str(bin(i))+":")
        bivariateProb=fm[(x0,x1)][i]/sum(fm[(x0,x1)])  
        
        if (bivariateProb!=0 and univariateProbX0[indX0]!=0 and univariateProbX1[indX1]!=0):
            #print("parcial mutuals:"+str(bivariateProb* math.log(bivariateProb/(univariateProbX0*univariateProbX1))))
            mutual= mutual+(bivariateProb* math.log(bivariateProb/(univariateProbX0[indX0]*univariateProbX1[indX1])))
        
    return mutual


def dfs_edges(G, source=None, depth_limit=None, vbse=False):
    """
    This function is based on the Depth First function of the networkx library. 
    Modificarions have been done in order to go creating the bits of the individuals while traversing the tree.

    Iterate over edges in a depth-first-search (DFS).

    Parameters
    ----------
    G : NetworkX graph

    source : node, optional
       Specify starting node for depth-first search and return edges in
       the component reachable from source.

    depth_limit : int, optional (default=len(G))
       Specify the maximum search depth.

    Returns
    -------
    edges: generator
       A generator of edges in the depth-first-search.

    Examples
    --------
    >>> G = nx.path_graph(5)
    >>> list(nx.dfs_edges(G, source=0))
    [(0, 1), (1, 2), (2, 3), (3, 4)]
    >>> list(nx.dfs_edges(G, source=0, depth_limit=2))
    [(0, 1), (1, 2)]
"""
    global newIndividual
    if source is None:
        # edges for all components
        nodes = G
    else:
        # edges for components with source
        nodes = [source]
    visited = set()
    if depth_limit is None:
        depth_limit = len(G)
    for start in nodes:
        if start in visited:
            continue
        visited.add(start)
        stack = [(start, depth_limit, iter(G[start]))]
        
        newIndividual[start]=np.random.choice(2,p=getUnivariate(start))
        if vbse:
            print("for x"+str(start)+" creates:"+ str(newIndividual[start]))
        while stack:
            parent, depth_now, children = stack[-1]
            try:
                child = next(children)
                if child not in visited:
                    yield parent, child
                    visited.add(child)
                    if depth_now > 1:
                        
                        stack.append((child, depth_now - 1, iter(G[child])))
                        newIndividual[child]=np.random.choice(2,p=getConditionalFrequency(parent,child,newIndividual[parent]))
                        if vbse:
                            print("for x"+str(child)+" creates:"+ str(newIndividual[child]))
            except StopIteration:

                stack.pop() 
               

def dfs_successors(G, source=None, depth_limit=None, vbse=False):
    """Return dictionary of successors in depth-first-search from source.

    Parameters
    ----------
    G : NetworkX graph

    source : node, optional
       Specify starting node for depth-first search and return edges in
       the component reachable from source.

    depth_limit : int, optional (default=len(G))
       Specify the maximum search depth.

    Returns
    -------
    succ: dict
       A dictionary with nodes as keys and list of successor nodes as values.

    Examples
    --------
    >>> G = nx.path_graph(5)
    >>> nx.dfs_successors(G, source=0)
    {0: [1], 1: [2], 2: [3], 3: [4]}
    >>> nx.dfs_successors(G, source=0, depth_limit=2)
    {0: [1], 1: [2]}

    Notes
    -----
    If a source is not specified then a source is chosen arbitrarily and
    repeatedly until all components in the graph are searched.

    The implementation of this function is adapted from David Eppstein's
    depth-first search function in `PADS`_, with modifications
    to allow depth limits based on the Wikipedia article
    "`Depth-limited search`_".

    .. _PADS: http://www.ics.uci.edu/~eppstein/PADS
    .. _Depth-limited search: https://en.wikipedia.org/wiki/Depth-limited_search
    """
    d = defaultdict(list)
    for s, t in dfs_edges(G, source=None, depth_limit=depth_limit, vbse=vbse):
        d[s].append(t)

    return dict(d) 

def applyDecayfactor(factor):
# Decreases the values of all elements of the frequency matrix by a given factor 
   
    global fm
    for key in fm:
            fm[key]*=factor
   
def addFrequenciestoMatrix(selectedPop):
# Adds the frequencies corresponding to the selected population to the frequency matrix  
    global fm
    for i in range(numvar):
        for j in range(i+1,numvar):
            for k in range(len(selectedPop)):
                 fm[(i,j)][selectedPop[k][j]+selectedPop[k][i]*  2]+=1
     

def createMSPfromMI(verbose=False):
# This function creates a graph which contains the minimum spanning tree. In order to do so, it iterates all the variable-pair combinations 
# the frequency matrix,calculating the Mutual Information. This value is added as the weight to the edges that represent the variable-pairs in the 
# Mutual Information graph. Then this graph is used to create the graph with the minimum spanning tree.

   # MIGraph=nx.empty_graph(numvar)
    MIGraph=nx.empty_graph(numvar)
 
    for i in range(numvar):
        for j in range(i+1,numvar):
             MIGraph.add_edge(i,j,weight=getMutualInfo(i,j)*-1)
            
    if verbose:
         print("THE ENTIRE GRAPH\n")
         print(sorted(MIGraph.edges(data=True))) 
         print("THE NODE CONNECTIONS OF THE MINIMUM TREE:\n")
         print(nx.minimum_spanning_tree(MIGraph).edges(data=True))
         
    return nx.minimum_spanning_tree(MIGraph)


def traverseTree(T, vbse=False):
# Traverse the tree for creating the new individuals

    for i in range(len(population)):
        dfs_successors(T,vbse=vbse)
        for j in range(numvar):
            population[i][j]=newIndividual[j]
    
   
def treeEDA(population,toolbox, ngen, halloffame=None, stats=None,verbose=__debug__,vbse=False):
# This function executes the treeEDA algorithm     
    init(1000.0,len(population[0]), population)
 
    #addFrequenciestoMatrix() 
    logbook = tools.Logbook() 
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])
    
    for gen in range (ngen):
        tree=createMSPfromMI(verbose=False)
        traverseTree(tree,vbse=False)
        
        fitnesses = toolbox.map(toolbox.evaluate, population)
        for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit

        # Select sizeOfSelection individuals according to the best fitness
        sizeOfSelection=int(sys.argv[1:][4])
        selPop= toolbox.select(population, sizeOfSelection)        
        
        record = stats.compile(population) if stats is not None else {}
        logbook.record(gen=gen, nevals=len(population), **record)
        if verbose:
                  print(logbook.stream)
        #Apply the decay factor to all elements of the frequency matrix
        applyDecayfactor(0.99)
        addFrequenciestoMatrix(selPop) 
    
    return population, logbook